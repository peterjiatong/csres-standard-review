#æ›´æ–°æŠ¥å‘Šä¸­çš„æ ‡å‡†.py
import logging
import pandas as pd
from pathlib import Path
import requests
import time

from util import (
    setup_logging, MONTH_DAY, load_existing_data,
    SRC_FILE, update_std_index, extract_from_docx, get_jar, BASE_URL, HEADERS,
    process_code, remove_duplicates, get_path_for_report_folder,
    normalize_name, save_excel_with_formatting, get_path_for_log_file,
    DEST_FILE, generate_new_standards_report_in_exist_folder

)

CURRENT = {"çŽ°è¡Œ", "å³å°†å®žæ–½"}

sheet_map = [
    "æœ‰æœç´¢ç»“æžœçš„æ ‡å‡†",
    "æ— æœç´¢ç»“æžœæˆ–æœç´¢ç»“æžœè¿‡å¤šçš„æ ‡å‡†",
    "æ ‡å‡†æ— è¯¦ç»†æ—¥æœŸ(debugç”¨)",
    "æŠ¥é”™(debugç”¨)",
]

dfs = pd.read_excel(SRC_FILE, sheet_name=sheet_map)
df_has_output                    = dfs["æœ‰æœç´¢ç»“æžœçš„æ ‡å‡†"]
df_no_output_or_too_much_outputs = dfs["æ— æœç´¢ç»“æžœæˆ–æœç´¢ç»“æžœè¿‡å¤šçš„æ ‡å‡†"]
df_date_empty                    = dfs["æ ‡å‡†æ— è¯¦ç»†æ—¥æœŸ(debugç”¨)"]
df_err                           = dfs["æŠ¥é”™(debugç”¨)"]

STD_INDEX = update_std_index(df_has_output)

def related_warnings(code: str) -> str | None:
    """
    é’ˆå¯¹  /XGâ€¦ ä¿®æ”¹å• ä»¥åŠ â€œEâ€ è‹±æ–‡ç‰ˆ çš„è¡¥å……æé†’  
    - è¿”å›ž None è¡¨ç¤ºæ²¡æœ‰é¢å¤–æé†’ï¼›å¦åˆ™è¿”å›žä¸€æ®µå‘Šè­¦æ–‡å­—
    """
    # 1ï¸âƒ£  è‹±æ–‡ç‰ˆ (â€¦E)
    if not code.endswith("E"):
        eng_code = f"{code}E"
        if eng_code in STD_INDEX:                 # è‹±æ–‡ç‰ˆå­˜åœ¨
            return f"(å‘çŽ°è‹±æ–‡ç‰ˆ {eng_code})"

    # 2ï¸âƒ£  ä¿®æ”¹å•  (/XGn-yyyy)
    base, _, tail = code.partition("/XG")
    if _ == "":                                   # ä¼ å…¥çš„ä¸æ˜¯â€œä¿®æ”¹å•â€æœ¬èº«
        # æŸ¥æ‰¾æ‰€æœ‰åŒåŸºå‡†çš„ /XG
        mods = sorted(k for k in STD_INDEX if k.startswith(f"{base}/XG"))
        if mods:
            return f"(å­˜åœ¨ {len(mods)} ä¸ªä¿®æ”¹å•ï¼š{', '.join(mods)})"
    else:                                         # ä¼ å…¥çš„æ˜¯æŸä¸ªä¿®æ”¹å•
        try:
            cur_idx = int(tail.split("-")[0])     # /XG1-2022 â†’ 1
        except Exception:
            cur_idx = -1
        higher = sorted(
            k for k in STD_INDEX
            if k.startswith(f"{base}/XG")
            and int(k.split("/XG")[1].split("-")[0]) > cur_idx
        )
        if higher:
            return f"(å­˜åœ¨æ›´æ–°çš„åºå·ä¿®æ”¹å•ï¼š{', '.join(higher)})"
        else:
            return "ï¼ˆå·²æ˜¯æœ€æ–°ä¿®æ”¹å•ï¼‰"

    return None

def check_one(code: str, name: str):
    """è¿”å›ž (ok?, message)"""
    warn = related_warnings(code)
    if code not in STD_INDEX:
        return "no_exist", "æ ‡å‡†åº“æœªæ”¶å½•ï¼ˆæ ‡å‡†ç¼–å·æœ‰è¯¯æˆ–ä¸å­˜åœ¨ï¼‰"
    
    # Get status, std_name, and replacement info from STD_INDEX
    status, std_name, replacement_info = STD_INDEX[code]
    
    if status not in CURRENT:
        # Add replacement info to status_wrong message if available
        status_msg = f"çŠ¶æ€å¼‚å¸¸ï¼ˆ{status}ï¼‰"
        if replacement_info and replacement_info.strip():
            status_msg += f" | æ›¿ä»£æƒ…å†µï¼š{replacement_info}"
        return "status_wrong", status_msg
    
    if warn:
        if normalize_name(name) != normalize_name(std_name):
            return "name_wrong", f"{warn} | åç§°ä¸ç¬¦ "
        return "ok", f"OKï¼›{warn}"
    
    if normalize_name(name) != normalize_name(std_name):
            return "name_wrong", "åç§°ä¸ç¬¦"
    return "ok", "OK"

def main():
    global STD_INDEX, df_has_output, df_no_output_or_too_much_outputs, df_date_empty, df_err
    setup_logging("check_report_log.txt")
    logging.debug("--" * 30)
    logging.info(f"æ›´æ–°æ•°æ®åº“.py - ç¨‹åºå¼€å§‹è¿è¡Œ - {MONTH_DAY}")
    logging.debug("--" * 30)

    code_ok, code_err, known_codes = load_existing_data()
    codes = []
    code_to_process = []
    for docx in sorted(Path("reports").glob("*.docx")):
        hits = extract_from_docx(docx)
        if not hits:
            continue

        for _, (_, code, _) in enumerate(hits, 1):
            if code not in codes:
                codes.append(code)
                if code not in STD_INDEX:
                    code_to_process.append(code)

    logging.debug(f"å¾…å¤„ç†æ ‡å‡†ä»£ç é•¿åº¦ï¼š{len(code_to_process)}")

    jar = get_jar()

    session = requests.Session()
    session.cookies.update(jar)
    logging.info("å·²æ›´æ–°cookie jar")

    try:
        session.get(BASE_URL, headers=HEADERS, timeout=(5, 15))
        logging.info("æˆåŠŸè®¿é—®åŸºç¡€URL")
    except requests.ReadTimeout:
        logging.error("è¯·æ±‚è¶…æ—¶, ç¨‹åºç»“æŸï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥æˆ–ç›®æ ‡ç½‘ç«™çŠ¶æ€")
        print("è¯·æ±‚è¶…æ—¶, ç¨‹åºç»“æŸï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥æˆ–ç›®æ ‡ç½‘ç«™çŠ¶æ€")
        return

    for i, code in enumerate(code_to_process, 1):
        logging.info(f"æ›´æ–°â€œæœ‰æœç´¢ç»“æžœçš„æ ‡å‡†â€è¡¨[{i}/{len(code_to_process)}]")
        print(f"æ­£åœ¨å°è¯•æ›´æ–°æ ‡å‡† {i}/{len(code_to_process)}: {code}")
        process_code(code, session, df_has_output, df_no_output_or_too_much_outputs, df_date_empty, df_err, False)
        time.sleep(1.0)
    

    session.close()
    df_has_output, df_no_output_or_too_much_outputs, df_date_empty, df_err = remove_duplicates(
        df_has_output, df_no_output_or_too_much_outputs, df_date_empty, df_err
    )

    save_excel_with_formatting(DEST_FILE, df_has_output, df_no_output_or_too_much_outputs, df_date_empty, df_err)
    logging.info(f"âš™ï¸  å·²ç»ä¿å­˜æ ‡å‡†åº“è‡³{DEST_FILE}")
    excel_log_path = get_path_for_log_file("log_excel", "standard_details.xlsx")
    save_excel_with_formatting(excel_log_path, df_has_output, df_no_output_or_too_much_outputs, df_date_empty, df_err)
    logging.info(f"âš™ï¸  é¢å¤–ä¿å­˜æ—¥å¿—æ–‡ä»¶: {excel_log_path}")
    print("æ ‡å‡†åº“æ›´æ–°å®Œæˆ")
    print("å·²ä¿å­˜æ ‡å‡†åº“ï¼Œå¹¶ä¿å­˜äº†æ—¥å¿—æ ‡å‡†åº“")
    print("å¼€å§‹æ£€æŸ¥æŠ¥å‘Š")

    STD_INDEX = update_std_index(df_has_output)

    out_txt = get_path_for_report_folder("æ£€æŸ¥æŠ¥å‘Šä¸­çš„æ ‡å‡†.pyçš„è¿è¡Œç»“æžœ", "æ ‡å‡†æ£€æŸ¥æŠ¥å‘Š.txt")
    with out_txt.open("w", encoding="utf-8") as log_f:
        for docx in sorted(Path("reports").glob("*.docx")):
            logging.info("-" * 50)
            print(f"æ­£åœ¨æ£€æŸ¥æŠ¥å‘Šï¼š{docx.name}")
            print("-" * 50, file=log_f)

            hits = extract_from_docx(docx)
            header = f"\nðŸ“„ {docx.name} â€”â€” å…±å‘çŽ° {len(hits)} æ¡æ ‡å‡†å¼•ç”¨"
            logging.info(header)
            print(header, file=log_f)

            if not hits:
                continue

            for idx, (orig_code, code, name) in enumerate(hits, 1):
                status, msg = check_one(code, name)
                flag = "âœ…" if status == "ok" else "âŒ"
                if status == "no_exist":
                    line = f"{idx:>2}. {flag} {orig_code:<25} | {msg:<10} \n"
                elif status == "status_wrong":
                    line = f"{idx:>2}. {flag} {orig_code:<25} | {msg:<10} \n"
                elif status == "name_wrong":
                    try:
                        correct_name = df_has_output.loc[df_has_output["æ ‡å‡†ç¼–å·"] == orig_code, "æ ‡å‡†åç§°"].iat[0]
                        line = f"{idx:>2}. {flag} {orig_code:<25} | {msg:<10} \t (æ­£ç¡®åç§°åº”ä¸ºï¼š{correct_name}) \n"
                    except:
                        line = f"{idx:>2}. {flag} {orig_code:<25} | (æœ¬æ¡æ ‡å‡†é—®é¢˜éœ€æ‰‹åŠ¨æŽ’æŸ¥ï¼‰\n"
                else:
                    line = f"{idx:>2}. {flag} {orig_code:<25} | {msg:<10} \n"
                logging.debug(line)
                print(line, file=log_f)

        logging.info("-" * 50)
        print("-" * 50, file=log_f)

    generate_new_standards_report_in_exist_folder(out_txt.parent, df_has_output, known_codes)
    logging.info(f"ç»“æžœå·²åŒæ—¶å†™å…¥ {out_txt}")
    logging.info("ç¨‹åºè¿è¡Œå®Œæˆ")
    print("ç¨‹åºè¿è¡Œå®Œæˆ")
    logging.info("--" * 30)

if __name__ == "__main__":
    main()
